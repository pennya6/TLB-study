## 논문명: 물리 모델 기반 데이터 증강을 통한 건전성 예측 및 관리(PHM) 기술

- **논문 저자**: 아시프칸, 이혜원, 김흥수

- **논문 url**: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10501519


논문 선정 이유: 우리가 진행하고 있는 티엘비 프로젝트는 데이터가 부족함.
               따라서 데이터 증강이 불가피한데 이를 뒷받침해줄 논문이 필요하다고 판단하여 선정함.
               


### 머리말

- 딥러닝 프레임 워크에서는 상당한 양의 상습 데이터가 필요하다.

- 건전성 예측 및 관리를 위한 딥러닝 접근방식의 사용은 매우 제한적이다.  
    
- 상당한 양의 정상상태 데이터를 제공하는 반면 고장상태의 데이터에 대해 매우 제한적이거나 아예 제공되지 않는다. 


    
        
        
### 데이터 증강 기술

- 모델의 일반화를 위해서는 다양한 건전성 상태의 데이터가 필요하다.    
 
- 서술한 바와 같이 고장 데이터 매우 적은데 이러한 데이터 불균형 조합은 다수의 클래스인 정상상태 예측으로 편향시킨다. 따라서 정확성을          담보하지 못한다.    
 
- 산업환경에서 상태 모니터링 센서는 일반적으로 시계열 형식인데 CNN을 이용하기 위해 시계열 데이터를 이미지 데이터로 변환하여 해석한다.     

- 이미지 변환은 FFT, 연속 웨이블릿 변환을 통한 스칼로그램, GAF(gramian angular fields), MTF(markov transition fields) 및               RP(recurrence plots)가 있다.

- 이미지 증강 알고리즘에는 여러가지 형태가 있다.
       
  1. 기하학적 변환: 기하학적인 변환을 사용해 경우의 수를 확대하는 방법을 주로 사용하는데, 이미지의 좌우 반전, 상하 반전,
                위치 이동, 회전, 
                크기 조정, 큰 영상에서 일부만 잘라내기와 같은 것들이 있다.
                      
  2. 색공간 증강: 색을 섞거나 조도 및 채도를 조절함
        
       
  3. 특징공간 증강(feature space augmentation): 특징이 있는 공간에서만 보간(함수값을 추정)과 
                                            외삽(그래프의 끝 두점과 데이터를 알고있을때 전체적인 그래프를 추정하는것)
                         
  4. 생성적 적대 신경망(GAN): 실제와 가까운 이미지, 동영상, 음성 등을 자동으로 만들어 내는 기계학습 방식
        
  5. 스타일 전이학습 및 메타학습: 특정 환경에서 만들어진 AI 알고리즘을 다른분야에 적용, 
                                AI에게 문제 해결에 필요한 학습 방법을 알려주는 기술.
                                
                                
                                
                                

## 논문명: 다변량 시계열 데이터에서 이상 탐지를 위한 지식 증류

- **논문 저자**: 김선영, 김명호

- **논문 url**: https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10583146




### 서론

- 이상탐지는 다변량 시계열 데이터를 분석하여 고장이나 위험 상황과 이상 상황을 탐지하는 기술이다.

- LSTM을 이용하여 이상상황을 탐지한다

- 성능 향상을 위해 딥러닝 모델 구조가 더 많은 층으로 이루어져 있어 추론 시간이 길어지는 문제가 있다.

- 위와 같은 문제점을 해결하고 효율성을 얻기위해 학습된 딥러닝 모델을 선생 모델로 활용하여 모델의 가중치 연산 수는 적지만 기존과 성능이 비슷한 지식 증류(knowledge distillation) 기법을 이상 탐지를 위한 딥러닝 모델에 적용

- AE 오토인코더 모델을 활용했다.




### 배경

- LSTM 오토인코더는 sequence-to-sequence 모델로 시퀀스 학습을 위한 모델이다.

- LSTM 오토인코더는 입력 시퀀스와 복원된 시퀀스의 차이를 최소화하다록 학습된다.

- 학습이 완료된 후 이상 상황을 탐지하기 위해 입력된 시퀀스에 대한 이상점수를 계산한다.




### 지식 증류 기법

- 지식 증류 기법은 큰 모델(선생 모델)이 가지고 있는 지식을 작은 모델(학생 모델)에게 전달하는 기법이다.

- 학생 모델은 선생 모델의 지식을 학습하는 과정을 통해 손실 함수가 빠르게 수렴 및 파라미터 개수는 작지만 비슷한 성능을 가지게 되어 
연산이 빠르다.

![화면 캡처 2021-08-09 014834](https://user-images.githubusercontent.com/84979999/128639319-32a74a6c-981b-4a32-8745-7246a1ed9a9f.png)

- 그림 1은 지식 증류를 통해 학습하는 과정을 묘사했다.

- 학습 데이터를 선생 모델이 먼저 학습하는데 이는 학생 모델에게 지식이 담겨있는 출력값을 전달해 주기 위함이다.

- 그 후 같은 학습 데이터를 사용하여 선생 모델에게서 얻은 출력값과 원래 데이터 라벨을 이용해서 학생 모델을 훈련시킨다.




### 제안 방법

![화면 캡처 2021-08-09 015333](https://user-images.githubusercontent.com/84979999/128639433-4fc35fd8-9b65-4896-82be-25f1024ef19f.png)

- 본 논문에서는 선생 모델로 LSTM 오토인코더를 사용했고 은닉 유닛수를 줄여 파라미터가 적은 LSTM을 오토인코더 학생 모델로 활용하였다.

- 학생 모델은 미리 훈련된 선생 모델이 복원한 시퀀스와 입력 시퀀스를 사용하여 학습한다.




### 실험

- 다변량 시계열 데이터를 활용하여 선생 모델과 학생 모델의 이상 탐지 성능을 측정하였다.

- 이상인 데이터를 양성, 정상인 데이터를 음성으로 탐지하였다.

- Precision, Recall, F1 점수를 활용함

![image](https://user-images.githubusercontent.com/84979999/128639543-e3a289a7-2a71-42d6-b170-98c5567e66d3.png)

![image](https://user-images.githubusercontent.com/84979999/128639561-7a9725e0-d5d5-4408-9b29-8ee5ee1dd85d.png)




  



      
