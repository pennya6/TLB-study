분석한 이 : 김시연

논문 제목 : LSTM 오토인코더를 이용한 라디에이터 고장진단 사례 연구(2020)
논문 저자 : 이정근, 김덕환

https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002673315


선택한 이유 : 유미님께서 LSTM AE에 대해서 이야기해주셨음, LSTM AE에 대해서 파악하던 중 진동신호를 취득, 라디에이터 고장 예측 진단 이라는 부분에서 예지보전 프로젝트와의 유사성이 있을 듯


+들어가기 앞서
1. 과연 LSTM은 무엇인가?
- 시계열 데이터의 이상감지는 시간적인 특성을 고려해야한다.
  단 시간적인 특성을 담고 싶다면 LSTM 네트워크를 이용해야 한다.
  따라서 기존의 오토인코더에 시간적 특성을 담을 수 없기 때문에 LSTM 레이어를 이용해 오토인코더를 구성해야한다.
  Sequence 데이터를 다루는 LSTM
  
2. AutoEncoder는 무엇인가?
- 비지도학습 인공지능
  데이터 압축, 저차원화를 통한 데이터 관계 관찰, 배경 잡음 억제 등에 활용
  입력된 데이터를 재구성해내는 기능을 가진 알고리즘
  
  즉 입력 데이터인 정상 데이터에 대한 특징을 학습 이후 학습된 모델에 데이터를 넣었을때 재구성한 결과와 학습된 정상 특징과의 차이점을 비교해 이상여부 판단
  
  부호화 과정과 복호화 과정이 연속적으로 일어나는 동작 과정
  
  지도학습 -> CNN
  비지도학습 -> Autoencoder, GAN
  
  지도학습이 비지도학습에 비해 학습된 모델의 정확도가 높다. 
  
  1. 단 비정상 Sample을 구하기 어렵다. 
  2. 새로운 이상패턴 발생시 새로 학습을 진행해야 한다.
  
  위의 2가지 문제점에 의해서 비지도 학습이 비교적
  활발하게 연구중이다.
  
  
논문 분석
1. 요약
- LSTM 오토인코더를 이용한 라디에이터 고장진단 수행
  라디에이터의 내구연한 랜덤 가진 시험에서 진동신호 취득
  Raw data에 10초 단위로 Window를 씌워 시간영역 통계적 특징 추출하여 변수 설정 이후 Sliding 기법으로 데이터 증강
  데이터는 4개의 stage로 구분 -> 1(정상), 2(정상), 4(비정상)
  stage 1을 훈련데이터
  stage 2, 4를 모델 최적화 및 평가 수행
  
  
  +궁긍즘
  - 내구연한 랜덤 가진 시험?
  -> 시험 중 가진을 통해 한 시스템의 변화 확인 및 이 시스템이 가지고 있는 문제를 발현하는 시간을 추출하기 위한 시험


2. 서론
- 라디에이터 파손은 설비의 진동과 라디에이터의 고유주파수가 공진하여 발생
  강제진동에 의해 누적되는 라디에이터 소재 튜브 용접부에서의 피로파괴 때문에 발생
  전통적인 신뢰성 분석은 고장시간 데이터와 확률분포를 기반으로 설비수명을 예측하지만 본 논문은 딥러닝을 활용한 PHM 기술을 활용하여 설비에서 발생하는 데이터를 기반으로 설비상태 변화를 관찰함
  
  
3. 라디에이터 데이터의 특징
3.1 라디에이터
- 라디에이터는 Fin & Tube 타입의 열 교환기이다.
  Tank - Tube - Fin 구조로 주로 알루미늄 합금 소재를 사용하며 열전도율이 높고 냉각 성능이 우수한 성징을 갖고있다. 
  설비에서 발생하는 진동으로 인해 라디에이터 용접부에서 파손이 발생하여 냉각수 누수 되는 현상이 발생한다.
  
3.2 내구 연한 랜덤 가진 시험
- 라디에이터 파괴를 모사하고 가속시험을 하기 위해서 설비에서 라디에이터에 가진 되는 진동 신호를 취득하고 내구 연한 랜덤 가진 시험을 수행하였다.
  가속시험은 시험시간이나 시료 수의 감소를 위해 사용조건보다 가혹한 조건을 부과함으로써 고장 메커니즘을 축존시킨다.
  
3.3 데이터 라벨링
- 라디에이터에 8개의 가속도 센서를 부착하여 1초당 12800HZ로 총 808분 동안 신호 취득
  <표 1>과 같이 Labeling하여 Stage 1 데이터를 훈련데이터로 사용
  Stage 2,4 데이터중 70%를 파라미터 최적화를 위한 Validation 데이터로 설정, 30%는 완성된 모델의 metrics 평가를 위해 Test데이터로 활용
  Stage 3는 상태를 알 수 없어 학습된 LSTM 오토인코더  모델로 라디에이터의 고장 발생 여부를 상세 진단
  
3.4 실험 데이터의 Feature engineering
- 센서 1개당 가속도 시계열 데이터 구조는 12800(Hz) * 60(sec) * 808(min)으로 총 620,544,000개의 데이터
  데이터크기가 매우 커 분석에 비효율적 따라서 데이터를 압축하고자 윈도우(10 sec)마다 최소, 최대, 절댓값, 평균, 분산, RMS, 왜도, 첨도와 같은 7개 통계적 특징을 추출하여 총 56개의 변수 생성
  Sliding 기법(그림 4)을 사용하여 데이터응 Augmentation하여 충분한 훈련 데이터를 확보
  따라서 변수하나당 총 48471개의 데이터 확보

  +궁금증
  -과연 데이터가 줄었을까?
  -> 48471 * 56 = 2,714,376 그전의 데이터 크기보다 확연히 줄었다.
  
  
4. 딥러닝 모델 선정 및 배경
4.1 LSTM 오토인코더
- 오토인코더는 레이블 되어 있지 않은 훈련 데이터를 사용해서 입력 데이터의 효율적인 표현인 코딩을 학습할 수 있는 인공신경망이다.
  일반적으로 입력보다 훨씬 낮은 차원을 가짐으로 차원 축소에 유용하게 사용된다. 
  오토인코더는 입력을 내부 표현으로 바꾸는 인코더와 내부 표현을 출력으로 바꾸는 디코더로 구성되어있다.
  오토인코더가 입력을 재구성하기 때문에 출력 결과를 재구성이라고 부른다. 
  본 논문에서는 MSE(Mean Square Error)를 재구성 손실로 사용하여 학습을 수행하였다.
  
  LSTM은 인공순환 신경망 구조의 하나로 기존의 순환 신경망(RNN)의 경사 사라짐 문제를 해결하기 위해 고안되었다.
  LSTM은 장기 상태 값과 단기 상태 값을 가지고 학습하여 학습 시간이 오래 지속되어도 경사 사라짐 문제 없이 학습 될 수 있다.
  본 논문에서는 두개의 LSTM 층을 이용하여 각각 인코더와 디코더로 사용되는 LSTM 오토인코더를 구현하였다..
  
  (그림 5)
  
  LSTM 오토인코더에서 성능을 향상시키고 과적합을 방지하기 위해서 은닉층 노드의 수, 드롭아웃 비율과 L2 정규화 파라미터를 변경하여 최적화 수행하였다.
  추가적으로 은닉층을 추가하고 Stacked LSTM 오토인코더를 구성하여 단일층 LSTM 오토인코더와 성능 비교를 수행하였다.
  
4.2 기존 연구와의 차이점
- 최근 연구에서 고장 진단을 위해서 사용하는 분류기로 신경망 회로와 서포트 벡터 머신(SVM)을 대표적으로 이용한다.
  하지만 이런 분류기는 사전에 분류기에 학습하여 이상치를 감지해야 하는 지도학습 및 Data-driven 문제 해결의 한계를 갖고 있다.
  
  LSTM 오토인코더를 활용한 고장진단은 기존 분류기와 달리, 정상 데이터 학습만으로 이상치를 감지하여 범용적으로 고장을 진단할 수 있다는 강점이 있다.
  -> 이 부분이 LSTM AE을 이용하는 가장 큰 이유라고 생각, 저희도 만약에 예지보전 프로젝트를 주제로 진행하게 된다면 이런 부분을 고려해서 모델을 선정해야 할 것 같다.
  
5. 실험 및 결과
5.1 LSTM 오토인코더 Baseline 구조
- LSTM 오토인코더 모델의 구조는 은닉층과 은닉층 노드의 수, 드롭아웃 비율 및 L2 정규화 라파미터에 따라 달라진다.

 <표 2>

 LSTM cell의 경우 gate마다 활성화 함수가 sigmoid와 tanh 사용이 고정되어있음
 최적화 과정은 4개의 파라미터를 수정하여 레이블이 있는 검증 데이터(stage 2, 4)의 진단 정확도를 향상시키는 방향으로 수행하였다.
 모델 최적화를 위한 정상, 비정상 검증 데이터의 분류 임계점은 훈련 데이터 셋의 MSE 분포도의 99% 값을 초기값으로 설정하였다.
 +3sigma 수준의 99%를 초기임계점으로 설정하고 모델 최적화를 수행하였다.

5.2 LSTM 오토인코더 모델 최적화
- 딥러닝 모델의 가중치 경량화를 위해 노드의 수를 최소화하여 200으로 고정하고 드롭아웃 비율 최적화 수행하였다.
  드롭아웃을 적용하면 매 훈련 스텝에서 출력 뉴런을 제외한 각 입력 뉴런은 임시적으로 드롭 아웃될 확률 p를 가지게 된다.
  하이퍼파라미터 p를 드롭아웃 비율로 설정하여 과대적합을 해결하도록 도와준다.
  본 논문에서는 0-0.6으로 드롭아웃 비율을 변경하여 실험을 수행하였다.
  
  <표 5> -> 드롭 아웃 비율이 0.3일때 성능이 가장 우수
  
  추가성능 개선을 위해 L2 정규화를 적용하였다.
  L2 정규화는 개별 가중치 값을 제한하여 모델 복잡도를 줄이는 방법이다.

  <표 6> -> L2 정규화 파라미터 가 0.01때 성능이 가장 우수
  
  은닉층에 인코더와 디코더에 추가하여 Stacked LSTM Autoencoder로 구성하였다.
  오히려 성능이 떨어지는 결과를 확인하였다.
  <표 7>
  

5.3 Test Dataset의 평가 Metrics
- Precision과 Recall의 트레이드오프 관계를 확인
  <그림 7> -> ROC(Receiver operating characteristic) 곡선에서 AUC(Area under the curve)가 0.9942임을 확인 하였다.

5.4 LSTM 오토인코더를 이용한 상세 고장진단 결과
- 약 335-340분 부터 재구성 오차가 cut-off 임계점을 초과하며 고장징후가 발생했을을 확인할 수 있다.
  전체 데이터셋을 5분 동안 지수이동평균하고 임계점(+2sigma,+3sigma 및 cut-off 지점)을 조정하여 알람에 의한 조기진당 결과
  +2sigma 또는 cut-off 임계점을 기준으로 알람을 설정하여 치명적인 고장이 발생하는 시점보다 조기에 유지보전을 실시할 수 있다.


결론 
-> 논문에서 데이터의 특징에 대해서 작성한 걸 보았을때 저희도 데이터에 대한 특징을 빨리 분석하고 그에 해당하는 CNN, CNN+SVM, LSTM-AE 등등을 실험하는 필요가 있을 것 같다.
   데이터에대한 특징을 분석하는 작업이 필요하다. 한 분이 담당하셔서 정리해 주시면 좋을 것 같다.
   또한 모델에 대해서 자세한 설명은 좋았지만 데이터를 어떻게 전처리 하는지 더 자세하게 언급이 없던 부분이 아쉽다. 
